[
  
  {
    "title": "Following Along with UIC&#39;s CS 598 PROOF AUTOMATION",
    "url": "/posts/proof_automation/",
    "categories": "Proof Automation",
    "tags": "verification, proof assistants",
    "date": "2022-01-03 00:00:00 -0600",
    





    "snippet": "Dr. Talia Ringer is teaching a course on proof automation at the University of Illinois at Urbana-Champaign. I’ve been a programming language nerd since dabbling with Haskell and the like in undergrad, and I’m very interested in the whole area of “proving things about computation”. Naturally, this falls squarely into that intersection, so I’m going to be following along with the course as best as I can manage this semester. This ongoing blog post will be where I post my notes, thoughts, and some solutions (only the non-directly-copyable sort).Homework 1Chapters 1 and 3 of QED at Large: A Survey of Engineering of Formally Verified Software by Talia Ringer, Karl Palmskog, Ilya Sergey, Milos Gligoric, and Zachary Tatlock.Reading Thoughts:The reading assignment served as a good introduction to the history of interactive verification. I think would have liked some companion pieces on the real and potential broader impacts of verification in the world. That would have felt more complete in an “end-to-end” sense and helped me get excited about the topic.I have one question about the paper: what is the difference between program verifiers and the application of proof assistants to verifying programs? Section 1.2 of the paper discusses its scope, and notes that it will focus on the latter, but not the former. I’m unsure of the relationship between the topics specifically omitted from the scope, i.e. program verifiers, theorem provers, and constraint solvers, and the topic of focus, proof assistants in the context of software engineering.Homework Prompt:Section 3.3 lists exactly one machine learning system that has been verified in a proof assistant. Based on what you know so far, do you think there is much hope for verifying state-of-the-art machine learning systems inside of a proof assistant? If so, why and how? And if not, what do you think it would take to be able to formally verify state-of-the-art machine learning systems?Response:In short, if “state-of-the-art” refers to the darlings of the machine learning research community, I don’t think they will be touched by formal verification in any meaningful way for a long time. On the other hand, if state-of-the-art simply means the models being employed today on real problems, then I think there’s a lot more hope. The central problem with the models being studied by the ML research community (e.g., transformers and large language models), is the enchantment the ML community has with increasingly large parameter counts and increasingly sophisticated architectures. This trend makes reasoning about these models more and more difficult as it progresses, outpacing the progress of the verification community. What is needed in this context is time for computing resources and software to catch up. On the other hand, where the size of a model can be kept reasonable, and its use is sufficiently sensitive so as to warrant more effort on verification (e.g., medicine, cyber-physical systems), I think that it is possible to define specific properties that models must satisfy and to define the models themselves as well as their settings in a concrete enough way so as to be amenable to being formally reasoned about. I think a next step in this direction is in the intersection of formal reasoning and probability, as proving properties of statistical machine learning models can be prohibitively computationally expensive.Homework 2"
  },
  
  {
    "title": "Star Sets",
    "url": "/posts/starsets/",
    "categories": "Tutorials",
    "tags": "verification, star sets",
    "date": "2021-09-21 00:00:00 -0500",
    





    "snippet": "The star set, introduced in (Tran et al., 2019), is a construction that is central to my work right now, so I wrote up this tutorial to help explain it in a simple, motivated way to my collaborators. I’m sharing it here now for my students, and so that I have something to which I can direct the curious.(Note: this post is a work in progress, expect it to change)MotivationStar sets are a verification method created for calculating reachability1, i.e., answering the question of “if the set of all possible inputs is $X$, what are all possible outputs $Y$?”.The typical use of this question and answer in control is to decide whether the set of possible outputs overlaps at all with an unsafe set.Any non-empty intersection indicates an intervention to prevent the potentially unsafe action.DefinitionsThis section is going to use a lot of notation for readers who benefit from such things. If you’re interested in the main idea, don’t worry about the typeset math, just read the text and you’ll be able to understand everything that follows just as well.We’ll start by understanding what Star Sets are trying to accomplish, to represent neural network transformations on entire sets rather than individual inputs.The simplest case works best with DNNs defined only with fully connected (FC) layers and ReLU activations, so that’s what we’ll use in this tutorial.To establish some definitions, neural networks can be expressed as $y = f(x)$ where\\[x\\in\\mathbb{R}^m, y\\in\\mathbb{R}^n, f: \\mathbb{R}^m\\to\\mathbb{R}^n\\]We’re interested in efficiently calculating $Y = f(X)$ where $f$ is the same, but instead of indiviual inputs, we want to work with sets,\\[X\\subseteq\\mathbb{R}^m, Y=\\{y|y=f(x), x\\in X\\}\\]The question is how to represent the sets so that $Y$ can be calculated efficiently? Because we’re only considering neural networks with FC layers and ReLU activations, we’ll rewrite our $n$-layer DNN definition as\\[\\begin{aligned}f &amp;amp;= f_n \\circ f_{n-1} \\circ\\cdots\\circ f_2\\circ f_1 \\\\&amp;amp;= \\text{aff}_n\\circ\\text{ReLU}_{n-1}\\circ\\text{aff}_{n-1}\\circ\\cdots\\circ\\text{ReLU}_1\\circ\\text{aff}_1\\end{aligned}\\]where $f_i$ is the $i$th layer of the network and the final layer of the network isn’t activated.Using a set as input to each layer, choosing ReLU activations means that each layer’s output set to being closed under affine and ReLU operations.Post ScriptBibliographyTran, H.-D., Lopez, D. M., Musau, P., Yang, X., Nguyen, L. V., Xiang, W., &amp;amp; Johnson, T. T. (2019). Star-based reachability analysis of deep neural networks. International Symposium on Formal Methods, 670–686.Footnotes            I’m using them for something different, but that’s for another post. &amp;#8617;      "
  }
  
]

